{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "medspaCy comes with a default knowledge base which is loaded by default. While these rules will cover a large number of use cases, users will often want to customize or extend the modifiers included in a knowledge base. Users can define their own modifiers and control their behavior through the `ContextItem` class.\n",
    "\n",
    "In this notebook, we'll dive deeper into the `ConTextItem` and `TagObject` classes and show how to use them to add and customize new rules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import medspacy\n",
    "\n",
    "from medspacy.context import ConTextItem, ConTextComponent\n",
    "\n",
    "from medspacy.visualization import visualize_dep, visualize_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = medspacy.load(enable=[\"sentencizer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifiers\n",
    "## ConTextItem\n",
    "The knowledge base of cycontext is defined by ConTextItem objects. A ConTextItem is instantiated with a number of parameters which allow for defining and controlling modifier behavior, but we'll focus on these 4 primary arguments:\n",
    "\n",
    "- **literal** (str): The actual string of a concept. If pattern is None,\n",
    "    this string will be lower-cased and matched to the lower-case string.\n",
    "- **category** (str): The semantic class of the item.\n",
    "- **pattern** (list or None): A spaCy pattern to match using token attributes.\n",
    "    See https://spacy.io/usage/rule-based-matching.\n",
    "- **rule** (str): The directionality or action of a modifier.\n",
    "    One of (\"forward\", \"backward\", \"bidirectional\", or \"terminate\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TagObject\n",
    "\n",
    "When a ConTextItem is matched to a string of text, it generates a `TagObject` which is stored in `doc._.context_graph.modifiers`. If it modifies any targets, these relationships can be found as tuples in `doc._.context_graph.edges`. The TagObject also contains a reference to the original ConTextItem.\n",
    "\n",
    "In addition to the attributes of the original ItemData such as **literal** and **category**, a TagObject contains the following attributes:\n",
    "- **span**: The spaCy Span of the matched text\n",
    "- **scope**: The spaCy Span of the Doc which is within the TagObject's scope. Any targets in this scope will be modified by the TagObject\n",
    "- **start**: Start index\n",
    "- **end**: End index (non-inclusive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Default Rules\n",
    "When you instantiate `ConTextComponent`, a default list of `ConTextItem`s is loaded and included in the `context.item_data` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ConTextComponent(nlp, rules=\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.item_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(context.item_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(context.item_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(context.item_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the unique categories in the knowledge base by checking `context.categories`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Basic Usage\n",
    "Here, we'll load a blank context component and define our own item data. We'll an example we've seen earlier, where we need to negate **\"pneumonia\"**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"There is no evidence of pneumonia.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.ents = (Span(doc, 5, 6, \"CONDITION\"),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we instantiate context and pass in `rules=None` so that we have an empty knowledge base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ConTextComponent(nlp, rules=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.item_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define a ConTextItem with following arguments:\n",
    "- `literal=`**\"no evidence of\"**: This is the string of text which ConText will look for in the text (case insensitive)\n",
    "- `category=`**\"NEGATED_EXISTENCE\"**: The semantic class assigned to our modifier\n",
    "- `rule=`**\"forward\"**: This defines the *directionality* of the rule. A later example shows more examples of this\n",
    "\n",
    "We'll leave the other arguments blank. Next, we instantiate our ConTextItem as `item` and put it in a list called `item_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = ConTextItem(literal=\"no evidence of\", category=\"NEGATED_EXISTENCE\", rule=\"FORWARD\")\n",
    "item_data = [item]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then add the modifiers to ConText with the `context.add()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.add(item_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.item_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call context on our doc. This will typically happen under the hood as part of the nlp pipeline, but you can call it manually on a doc as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see if any modifiers were created by context by looking at the `doc._.context_graph` attribute, which stores all of the information generated on a doc by context. `modifiers` stores the `TagObjects` created by context, and `edges` stores the relationships between the modifiers and targets. Here, we match a modifier with the custom `item_data` that we created, but there are no edges because there are no target concepts in `doc.ents` yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc._.context_graph)\n",
    "print(doc._.context_graph.modifiers)\n",
    "print(doc._.context_graph.edges)\n",
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dep(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element of `context_graph.modifiers` is a`TagObject`. Let's look at the tag object in this doc and see some of the attributes which are available: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_object = doc._.context_graph.modifiers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tag_object.span` is the spaCy Span of the Doc which was matched, and has a `start` and `end` index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tag_object.span)\n",
    "print(tag_object.start, tag_object.end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tag_object.scope` shows what part of the sentence could be modified by the modifier. Any targets in this span of text will be modified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tag_object.scope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the original `ConTextItem` object and attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tag_object.category, \",\", tag_object.rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reference to the original ConTextItem\n",
    "print(tag_object.context_item)\n",
    "assert tag_object.context_item is item_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Pattern-matching\n",
    "In this example, we'll use a matching pattern to generate a more flexible matching criteria to match multiple texts with a single ConTextItem. If only `literal` is supplied, the exact phrase is matched in lower case. spaCy offers powerful rule-based matching which operates on each token in a Doc. Matching patterns can use the text, regular expression patterns, linguistic attributes such as part of speech, and operators such as **\"?\"** (0 or 1) or **\"*\"** (0 or more) to match sequences of text. \n",
    "\n",
    "For more detailed information, see spaCy's documentation on rule-based matching: https://spacy.io/usage/rule-based-matching.\n",
    "\n",
    "The ConTextItem below has the same literal, categorym, and rule as our previous example, but it also includes a pattern which allows the tokens \"evidence\" and \"of\" to be optional. This will then match both \"no evidence of\" and \"no\" and assign both spans of text to be negation modifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = [ConTextItem(literal=\"no evidence of\", \n",
    "                         category=\"NEGATED_EXISTENCE\", \n",
    "                         rule=\"forward\", \n",
    "                         pattern=[{\"LOWER\": \"no\"}, \n",
    "                                  {\"LOWER\": \"evidence\", \"OP\": \"?\"},\n",
    "                                  {\"LOWER\": \"of\", \"OP\": \"?\"},\n",
    "                                 ]\n",
    "                        )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ConTextComponent(nlp)\n",
    "context.add(item_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"THERE IS NO EVIDENCE OF PNEUMONIA.\",\n",
    "        \"There is no CHF.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(nlp.pipe(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add entities\n",
    "docs[0].ents = (Span(docs[0], 5, 6, \"CONDITION\"),)\n",
    "docs[1].ents = (Span(docs[1], 3, 4, \"CONDITION\"),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    context(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0]._.context_graph.modifiers)\n",
    "visualize_dep(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[1]._.context_graph.modifiers)\n",
    "visualize_dep(docs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use regular expressions as the `pattern` argument, although this isn't recommend since spaCy doesn't natively support regular expression matching and may result in unexpected spans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = [\n",
    "    ConTextItem(\"no known history of\", \"HISTORICAL\", pattern=r\"no known (hx|history)\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.add(item_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"There is no known hx of pneumonia.\")\n",
    "doc.ents = (Span(docs[0], 5, 6, \"CONDITION\"),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dep(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: `rule` argument\n",
    "The `rule` attribute defines which direction modifiers should operate. You can imagine an arrow starting at the modifier in a phrase and moving *towards* the target. \n",
    "\n",
    "This argument can take one of 5 values. In this notebook, we'll explain the primary 3:\n",
    "- **FORWARD**: If the modifier comes before the target, the arrow will move **forward** in the sentence all targets in the sentence *after* the TagObject will be modified. \n",
    "- **\"BACKWARD\"**: The arrow will move **backward** in the sentence and match all targets *before*. \n",
    "- **\"BIDIRECTIONAL\"**: It will look **both ahead and behind** (this is the default).\n",
    "\n",
    "The additional values, **\"TERMINATE\"** and **\"PSEUDO\"**, will be explained in the next notebook.\n",
    "\n",
    "## Modifier Scope\n",
    "\n",
    "The scope of a modifier is bounded to be within the same sentence, so no modifier will affect targets in other sentences. This can be problematic in poorly split documents, but it prevents all targets in a document from being incorrectly modified by a ConText item. A scope is also defined by any termination points, which will be shown in the next example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = [ConTextItem(\"no evidence of\", \"NEGATED_EXISTENCE\", \"FORWARD\"),\n",
    "            ConTextItem(\"is ruled out\", \"NEGATED_EXISTENCE\", \"BACKWARD\"),\n",
    "             ConTextItem(\"unlikely\", \"POSSIBLE_EXISTENCE\", \"BIDIRECTIONAL\"),\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"No evidence of pneumonia.\",\n",
    "        \"PE is ruled out\",\n",
    "        \"unlikely to be malignant\", \n",
    "        \"malignancy unlikely\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(nlp.pipe(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add entities\n",
    "docs[0].ents = (Span(docs[0], 3, 4, \"CONDITION\"),)\n",
    "docs[1].ents = (Span(docs[1], 0, 1, \"CONDITION\"),)\n",
    "docs[2].ents = (Span(docs[2], 3, 4, \"CONDITION\"),)\n",
    "docs[3].ents = (Span(docs[3], 0, 1, \"CONDITION\"),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ConTextComponent(nlp, rules=None)\n",
    "context.add(item_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    context(doc)\n",
    "    modifier = doc._.context_graph.modifiers[0]\n",
    "    print(modifier, modifier.rule)\n",
    "    visualize_dep(doc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Writing a Knowledge Base\n",
    "ConTextItems can be saved as JSON and read in, which allows a knowledge base to be reused and scaled. When you install `cycontext` with pip or `python setup.py install`, it includes a JSON file of default modifier rules.\n",
    "\n",
    "The filepath on your local machine can be accessed in the constant `DEFAULT_RULES_FILEPATH`. Let's look at the first 10 lines of this file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medspacy.context import DEFAULT_RULES_FILEPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(DEFAULT_RULES_FILEPATH) as f:\n",
    "    print(f.read()[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A JSON file of item data can be loaded with the `ConTextItem.from_json` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = ConTextItem.from_json(DEFAULT_RULES_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in item_data[:5]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The items can also be saved as JSON by using the `ConTextItem.to_json` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConTextItem.to_json(item_data[:2], \"2_modifiers.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"2_modifiers.json\") as f:\n",
    "    print(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "The next notebook will show more complex examples of controlling modifier behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
