         85615 function calls in 0.100 seconds

   Ordered by: call count

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     4876    0.000    0.000    0.000    0.000 tokenizer.pyx:90(__get__)
     3846    0.000    0.000    0.000    0.000 tokenizer.pyx:98(__get__)
     3792    0.000    0.000    0.000    0.000 tokenizer.pyx:106(__get__)
     3460    0.001    0.000    0.002    0.000 doc.pyx:405(has_annotation)
     3460    0.000    0.000    0.000    0.000 doc.pyx:439(genexpr)
     3405    0.000    0.000    0.009    0.000 vocab.pyx:151(get_by_orth)
     2770    0.000    0.000    0.000    0.000 {method 'isalpha' of 'str' objects}
     2438    0.002    0.000    0.003    0.000 tokenizer.pyx:530(find_prefix)
     2414    0.000    0.000    0.000    0.000 {built-in method builtins.ord}
     2362    0.000    0.000    0.000    0.000 {method 'isupper' of 'str' objects}
     2317    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
     2009    0.001    0.000    0.002    0.000 vocab.pyx:131(get)
     2009    0.000    0.000    0.000    0.000 doc.pyx:889(__pyx_fuse_0push_back)
     1923    0.006    0.000    0.006    0.000 tokenizer.pyx:544(find_suffix)
     1896    0.005    0.000    0.006    0.000 tokenizer.pyx:516(find_infix)
     1780    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}
     1716    0.000    0.000    0.000    0.000 tokenizer.pyx:74(__get__)
     1424    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}
     1384    0.000    0.000    0.000    0.000 doc.pyx:487(__len__)
     1383    0.001    0.000    0.002    0.000 tokenizer.pyx:208(_flush_cache)
     1383    0.000    0.000    0.000    0.000 tokenizer.pyx:211(_reset_cache)
     1378    0.025    0.000    0.025    0.000 tokenizer.pyx:564(_validate_special_case)
     1378    0.004    0.000    0.097    0.000 tokenizer.pyx:582(add_special_case)
     1378    0.027    0.000    0.027    0.000 vocab.pyx:256(make_fused_token)
     1347    0.000    0.000    0.000    0.000 tokenizer.pyx:347(_try_specials_and_cache)
     1120    0.000    0.000    0.000    0.000 {method 'isdigit' of 'str' objects}
      896    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}
      896    0.000    0.000    0.000    0.000 abc.py:117(__instancecheck__)
      713    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}
      712    0.000    0.000    0.000    0.000 {built-in method unicodedata.category}
      712    0.000    0.000    0.000    0.000 lex_attrs.py:142(lower)
      711    0.000    0.000    0.000    0.000 {built-in method builtins.len}
      696    0.000    0.000    0.001    0.000 {built-in method builtins.isinstance}
      692    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}
      692    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}
      692    0.001    0.000    0.016    0.000 tokenizer.pyx:148(_tokenize_affixes)
      692    0.002    0.000    0.004    0.000 doc.pyx:177(__init__)
      692    0.000    0.000    0.012    0.000 tokenizer.pyx:376(_tokenize)
      692    0.001    0.000    0.005    0.000 tokenizer.pyx:388(_split_affixes)
      692    0.001    0.000    0.005    0.000 tokenizer.pyx:433(_attach_tokens)
      692    0.000    0.000    0.000    0.000 tokenizer.pyx:495(_save_cached)
      692    0.003    0.000    0.015    0.000 phrasematcher.pyx:156(add)
      692    0.001    0.000    0.009    0.000 vocab.pyx:232(__getitem__)
      692    0.000    0.000    0.000    0.000 phrasematcher.pyx:338(_convert_to_array)
      692    0.000    0.000    0.001    0.000 __init__.py:1043(__init__)
      692    0.001    0.000    0.002    0.000 _dict_proxies.py:22(__init__)
      692    0.000    0.000    0.001    0.000 _collections_abc.py:933(update)
      655    0.000    0.000    0.000    0.000 tokenizer.pyx:82(__get__)
      359    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}
      356    0.000    0.000    0.000    0.000 {method 'count' of 'str' objects}
      356    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}
      356    0.000    0.000    0.000    0.000 {method 'islower' of 'str' objects}
      356    0.000    0.000    0.000    0.000 {method 'istitle' of 'str' objects}
      356    0.000    0.000    0.000    0.000 {method 'isspace' of 'str' objects}
      356    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}
      356    0.000    0.000    0.000    0.000 util.py:1073(_get_attr_unless_lookup)
      356    0.001    0.000    0.001    0.000 lex_attrs.py:22(like_num)
      356    0.003    0.000    0.010    0.000 vocab.pyx:165(_new_lexeme)
      356    0.000    0.000    0.000    0.000 vocab.pyx:197(_add_lex_to_vocab)
      356    0.000    0.000    0.000    0.000 lex_attrs.py:25(is_punct)
      356    0.000    0.000    0.000    0.000 lex_attrs.py:32(is_ascii)
      356    0.000    0.000    0.000    0.000 lex_attrs.py:53(is_bracket)
      356    0.000    0.000    0.000    0.000 lex_attrs.py:58(is_quote)
      356    0.000    0.000    0.000    0.000 lex_attrs.py:65(is_left_punct)
      356    0.000    0.000    0.000    0.000 lex_attrs.py:72(is_right_punct)
      356    0.000    0.000    0.000    0.000 lex_attrs.py:77(is_currency)
      356    0.000    0.000    0.000    0.000 lex_attrs.py:85(like_email)
      356    0.000    0.000    0.001    0.000 lex_attrs.py:89(like_url)
      356    0.001    0.000    0.002    0.000 lex_attrs.py:115(word_shape)
      356    0.000    0.000    0.000    0.000 lex_attrs.py:146(prefix)
      356    0.000    0.000    0.000    0.000 lex_attrs.py:150(suffix)
      356    0.000    0.000    0.000    0.000 lex_attrs.py:154(is_alpha)
      356    0.000    0.000    0.000    0.000 lex_attrs.py:158(is_digit)
      356    0.000    0.000    0.000    0.000 lex_attrs.py:162(is_lower)
      356    0.000    0.000    0.000    0.000 lex_attrs.py:166(is_space)
      356    0.000    0.000    0.000    0.000 lex_attrs.py:170(is_title)
      356    0.000    0.000    0.000    0.000 lex_attrs.py:174(is_upper)
      356    0.000    0.000    0.000    0.000 lex_attrs.py:178(is_stop)
      356    0.000    0.000    0.000    0.000 lex_attrs.py:182(get_lang)
      202    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}
        6    0.002    0.000    0.099    0.017 tokenizer.pyx:558(_load_special_cases)
        6    0.000    0.000    0.000    0.000 phrasematcher.pyx:31(__init__)
        5    0.000    0.000    0.000    0.000 tokenizer.pyx:218(_flush_specials)
        5    0.000    0.000    0.000    0.000 tokenizer.pyx:608(_reload_special_cases)
        3    0.000    0.000    0.000    0.000 re.py:250(compile)
        3    0.000    0.000    0.000    0.000 re.py:289(_compile)
        1    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}
        1    0.000    0.000    0.000    0.000 {method 'translate' of 'str' objects}
        1    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
        1    0.000    0.000    0.000    0.000 re.py:270(escape)
        1    0.000    0.000    0.000    0.000 util.py:1034(<listcomp>)
        1    0.000    0.000    0.000    0.000 util.py:1027(compile_prefix_regex)
        1    0.000    0.000    0.000    0.000 util.py:1045(<listcomp>)
        1    0.000    0.000    0.000    0.000 util.py:1038(compile_suffix_regex)
        1    0.000    0.000    0.000    0.000 util.py:1056(<listcomp>)
        1    0.000    0.000    0.000    0.000 util.py:1049(compile_infix_regex)
        1    0.000    0.000    0.100    0.100 custom_tokenizer.py:10(create_medspacy_tokenizer)
        1    0.000    0.000    0.100    0.100 tokenizer.pyx:37(__init__)
        1    0.000    0.000    0.000    0.000 tokenizer.pyx:77(__set__)
        1    0.000    0.000    0.000    0.000 tokenizer.pyx:85(__set__)
        1    0.000    0.000    0.000    0.000 tokenizer.pyx:93(__set__)
        1    0.000    0.000    0.000    0.000 tokenizer.pyx:101(__set__)
        1    0.000    0.000    0.000    0.000 tokenizer.pyx:109(__set__)
        1    0.000    0.000    0.100    0.100 medspacy_profiler.py:35(fun_profiler)


